{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayotomiwaa/aml-numerai-2/blob/main/Numerai_EDA_%26_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP5khNLMaDHy",
        "outputId": "183ed82a-c796-4551-dcf5-eea9afd0707b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m357.3/357.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q numerapi pandas pyarrow matplotlib lightgbm scikit-learn cloudpickle lazypredict pandas-profiling\n",
        "\n",
        "# Inline plots\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAJbuNX2cPZN"
      },
      "source": [
        "## 1. Dataset  \n",
        "\n",
        "At a high level, the Numerai dataset is a tabular dataset that describes the stock market over time.\n",
        "\n",
        "Each row represents a stock at a specific point in time, where `id` is the stock id and the `era` is the date. The `features` describe the attributes of the stock (eg. P/E ratio) known on the date and the `target` is a measure of 20-day returns.\n",
        "\n",
        "The unique thing about Numerai's dataset is that it is `obfuscated`, which means that the underlying stock ids, feature names, and target definitions are anonymized. This makes it so that we can give this data out for free and so that it can be modeled without any financial domain knowledge (or bias!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8koHeUevbvTN"
      },
      "source": [
        "### Downloading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8q8ZWJobzhN",
        "outputId": "fd01e63d-fe66-4c1e-e1fd-7f20922e0a52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v4.2/features.json',\n",
              " 'v4.2/live_example_preds.csv',\n",
              " 'v4.2/live_example_preds.parquet',\n",
              " 'v4.2/live_int8.parquet',\n",
              " 'v4.2/meta_model.parquet',\n",
              " 'v4.2/train_int8.parquet',\n",
              " 'v4.2/validation_example_preds.csv',\n",
              " 'v4.2/validation_example_preds.parquet',\n",
              " 'v4.2/validation_int8.parquet']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Initialize NumerAPI - the official Python API client for Numerai\n",
        "from numerapi import NumerAPI\n",
        "napi = NumerAPI()\n",
        "\n",
        "# Print all files available for download in the latest dataset\n",
        "[f for f in napi.list_datasets() if f.startswith(\"v4.2\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "chhfM1IGb2kF",
        "outputId": "7f36530e-d38f-46ca-a0d0-1f3693891166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "v4.2/train_int8.parquet:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 964M/1.88G [00:56<01:10, 13.0MB/s]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# # Download the training data and feature metadata\n",
        "# # This will take a few minutes ğŸµ\n",
        "napi.download_dataset(\"v4.2/train_int8.parquet\");\n",
        "napi.download_dataset(\"v4.2/features.json\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1pPNAVBDcA39"
      },
      "outputs": [],
      "source": [
        "# Load only the \"medium\" feature set to reduce memory usage and speedup model training (required for Colab free tier)\n",
        "# Use the \"all\" feature set to use all features\n",
        "feature_metadata = json.load(open(\"v4.2/features.json\"))\n",
        "feature_cols = feature_metadata[\"feature_sets\"][\"medium\"]\n",
        "train = pd.read_parquet(\"v4.2/train_int8.parquet\", columns=[\"era\"] + feature_cols + [\"target\"])\n",
        "\n",
        "# Downsample to every 4th era to reduce memory usage and speedup model training (suggested for Colab free tier)\n",
        "# Comment out the line below to use all the data\n",
        "train = train[train[\"era\"].isin(train[\"era\"].unique()[::4])]\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnAy2cu_cVDV"
      },
      "source": [
        "### Eras\n",
        "As mentioned above, each `era` corresponds to a different date. Each era is exactly 1 week apart.\n",
        "\n",
        "It is helpful to think about rows of stocks within the same `era` as a single example. You will notice that throughout this notebook and other examples, we often talk about things \"per era\". For example, the number of rows per era represents the number of stocks in Numerai's investable universe on that date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "opPp4kd9cZf1"
      },
      "outputs": [],
      "source": [
        "# Plot the number of rows per era\n",
        "train.groupby(\"era\").size().plot(title=\"Number of rows per era\", figsize=(5, 3), xlabel=\"Era\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wovoAP-5cg1O"
      },
      "source": [
        "### Features\n",
        "As mentioned above, `features` are quantitative attributes of each stock: fundamentals like P/E ratio, technical signals like RSI, market data like short interest, secondary data like analyst ratings, and much more.\n",
        "\n",
        "The underlying definition of each feature is not important, just know that Numerai has included these features in the dataset because we believe they are predictive of the `target`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L0FX6zLFchzt"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4b4m1mvc4m-"
      },
      "source": [
        "Feature values are binned into 5 equal bins: `0`, `1`, `2`, `3`, `4`. This heavy regularization of feature values is to avoid overfitting as the underlying values are extremely noisy.\n",
        "\n",
        "If data for a particular feature is missing for that era (more common in early `eras`), then all values will be set to `2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xK2ZCaffc6HW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
        "first_era = train[train[\"era\"] == train[\"era\"].unique()[0]]\n",
        "last_era = train[train[\"era\"] == train[\"era\"].unique()[-1]]\n",
        "last_era[feature_cols[-1]].plot(kind=\"hist\", title=\"5 equal bins\", density=True, bins=50, ax=ax1);\n",
        "first_era[feature_cols[-1]].plot(kind=\"hist\", title=\"missing data\", density=True, bins=50, ax=ax2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39N-bMhwdCXW"
      },
      "source": [
        "### Target\n",
        "The `target` is a measure of 20-day stock market returns. Specifically, it is a measure of \"stock-specific\" returns that are not \"explained\" by broader trends in the market, country, sector, or well-known \"factors\".\n",
        "\n",
        "Target values are binned into 5 unequal bins: `0`, `0.25`, `0.5`, `0.75`, `1.0`. Again, this heavy regularization of target values is to avoid overfitting as the underlying values are extremely noisy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DUCcvoLTdDUW"
      },
      "outputs": [],
      "source": [
        "# Plot density histogram of the target\n",
        "train[\"target\"].plot(kind=\"hist\", title=\"Target\", figsize=(5, 3), xlabel=\"Value\", density=True, bins=50);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoaPjM9SdNLl"
      },
      "source": [
        "### Pandas Profiling Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jRFDboWydbAv"
      },
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(train, title=\"Profiling Report\", minimal=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0QrQ6Nu1eVFX"
      },
      "outputs": [],
      "source": [
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WZXVFYwygnd8"
      },
      "outputs": [],
      "source": [
        "profile.to_file(\"pandas_profile.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfQ9rv57M72v"
      },
      "source": [
        "### Reduce Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jizbhB37M-kA"
      },
      "outputs": [],
      "source": [
        "divisor = 10\n",
        "\n",
        "train = train.tail(int(train.shape[0]/divisor))\n",
        "\n",
        "import random\n",
        "\n",
        "# Calculate the number of features to select (a quarter of the total)\n",
        "num_features_to_select = len(feature_cols) // (divisor * 5)  # Use // for integer division\n",
        "\n",
        "# Randomly select a quarter of features\n",
        "selected_features = random.sample(feature_cols, num_features_to_select)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mymo6_kfEaC"
      },
      "source": [
        "### Baseline Modelling (AutoML)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GT2tQtzJfT2N"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# Define the features and target\n",
        "X = train[selected_features]\n",
        "y = train['target']\n",
        "\n",
        "# Split the data into training and testing sets stratified by multiple columns\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train[['era', 'target']]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PMlKNJ8znhUo"
      },
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RvH7k6Vpiba9"
      },
      "outputs": [],
      "source": [
        "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OKaxdBceVLSu"
      },
      "outputs": [],
      "source": [
        "models.head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOckfBnf/IyLkqQdoMD1W6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}